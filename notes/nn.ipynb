{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义numpy版本的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate, epochs):\n",
    "        # 输入层\n",
    "        self.input_nodes = input_nodes\n",
    "        # 隐藏层\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        # 输出层\n",
    "        self.output_nodes = output_nodes        \n",
    "        \n",
    "        # 激活函数\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "\t\t# 学习率\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # 训练批次\n",
    "        self.epochs = epochs\n",
    "\n",
    "\t\t# 要训练的权重矩阵：输入-隐层\n",
    "        self.w_input_hidden = numpy.random.normal(\n",
    "            0.0,\n",
    "            pow(self.hidden_nodes, -0.5),\n",
    "            (self.hidden_nodes, self.input_nodes)\n",
    "        )\n",
    "\n",
    "\t\t# 要训练的权重矩阵：隐层-输出\n",
    "        self.w_hidden_output = numpy.random.normal(\n",
    "            0.0,\n",
    "            pow(self.output_nodes, -0.5),\n",
    "            (self.output_nodes, self.hidden_nodes)\n",
    "        )\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \"\"\"\n",
    "        按批次训练\n",
    "         \"\"\"\n",
    "        for e in range(self.epochs):\n",
    "            self._step_train(inputs_list, targets_list)\n",
    "\n",
    "    def _step_train(self, inputs_list, targets_list):\n",
    "        \"\"\"\n",
    "        单个批次训练\n",
    "        \"\"\"\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = numpy.dot(self.w_input_hidden, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs = numpy.dot(self.w_hidden_output, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = numpy.dot(self.w_hidden_output.T, output_errors)\n",
    "        \n",
    "        self.w_hidden_output += self.learning_rate * numpy.dot(\n",
    "            output_errors * final_outputs * (1.0 - final_outputs),\n",
    "            numpy.transpose(hidden_outputs)\n",
    "        )\n",
    "        self.w_input_hidden += self.learning_rate * numpy.dot(\n",
    "            hidden_errors * hidden_outputs * (1.0 - hidden_outputs),\n",
    "            numpy.transpose(inputs)\n",
    "        )\n",
    "\n",
    "    def query(self, inputs_list):\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        hidden_inputs = numpy.dot(self.w_input_hidden, inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs = numpy.dot(self.w_hidden_output, hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"../data/mnist_train_100.csv\", \"r\")\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1312d88b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "all_values = data_list[5].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28, 28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练（使用 MINI 数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NeuralNetwork(input_nodes=784, hidden_nodes=200, output_nodes=10, learning_rate=0.2, epochs=2)\n",
    "\n",
    "training_data_file = open(\"../data/mnist_train_100.csv\", \"r\")\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "for record in training_data_list:\n",
    "    all_values = record.split(',')\n",
    "\n",
    "\t# 输入\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "\t# 目标值\n",
    "    targets = numpy.zeros(10) + 0.01\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "\n",
    "    n.train(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试（使用 MINI 数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_file = open(\"../data/mnist_test_10.csv\", \"r\")\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "7 correct_lable\n",
      "7 predict answer\n",
      "--------------------\n",
      "2 correct_lable\n",
      "2 predict answer\n",
      "--------------------\n",
      "1 correct_lable\n",
      "1 predict answer\n",
      "--------------------\n",
      "0 correct_lable\n",
      "0 predict answer\n",
      "--------------------\n",
      "4 correct_lable\n",
      "4 predict answer\n",
      "--------------------\n",
      "1 correct_lable\n",
      "1 predict answer\n",
      "--------------------\n",
      "4 correct_lable\n",
      "7 predict answer\n",
      "--------------------\n",
      "9 correct_lable\n",
      "3 predict answer\n",
      "--------------------\n",
      "5 correct_lable\n",
      "4 predict answer\n",
      "--------------------\n",
      "9 correct_lable\n",
      "7 predict answer\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "score_card = []\n",
    "\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(\",\")\n",
    "    correct_label = int(all_values[0])\n",
    "    print(\"-\"*20)\n",
    "    print(correct_label, \"correct_lable\")\n",
    "    \n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    \n",
    "    outputs = n.query(inputs)\n",
    "    label = numpy.argmax(outputs)\n",
    "    print(label, \"predict answer\")\n",
    "    \n",
    "    if label == correct_label:\n",
    "        score_card.append(1)\n",
    "    else:\n",
    "        score_card.append(0)\n",
    "\n",
    "print(score_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练（使用完整数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NeuralNetwork(input_nodes=784, hidden_nodes=200, output_nodes=10, learning_rate=0.1, epochs=5)\n",
    "\n",
    "training_data_file = open(\"../data/large_data/mnist_train.csv\", \"r\")\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "for record in training_data_list:\n",
    "    all_values = record.split(',')\n",
    "\n",
    "\t# 输入\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "\t# 目标值\n",
    "    targets = numpy.zeros(10) + 0.01\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    \n",
    "    n.train(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试（使用完整数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_file = open(\"../data/large_data/mnist_test.csv\", \"r\")\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "performance =  0.9465\n"
     ]
    }
   ],
   "source": [
    "score_card = []\n",
    "\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(\",\")\n",
    "    correct_label = int(all_values[0])\n",
    "    # print(\"-\"*20)\n",
    "    # print(correct_label, \"correct_lable\")\n",
    "    \n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    \n",
    "    outputs = n.query(inputs)\n",
    "    label = numpy.argmax(outputs)\n",
    "    # print(label, \"predict answer\")\n",
    "    \n",
    "    if label == correct_label:\n",
    "        score_card.append(1)\n",
    "    else:\n",
    "        score_card.append(0)\n",
    "\n",
    "print(score_card[:20])\n",
    "score_card_array = numpy.asarray(score_card)\n",
    "print(\"performance = \", score_card_array.sum() / score_card_array.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义pytorch版本的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TEST_BACTH_SIZE = 1000\n",
    "EPOCHS = 5\n",
    "LR = 0.01\n",
    "SEED = 42\n",
    "LOG_INTERVAL = 100\n",
    "\n",
    "# 定义一个全连接网络\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 第一层784维输入、256维输出 -- 图像大小28×28=784\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        # 第二层256维输入、128维输出\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        # 第三层128维输入、64维输出\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        # 第四层64维输入、10维输出 -- 输出类别10类（0,1,...9）\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 把输入展平成1D向量\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # 每层激活函数是ReLU，额外加dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # 输出为10维概率分布\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 训练过程\n",
    "def train(model, loss_fn, device, train_loader, optimizer, epoch):\n",
    "    # 开启梯度计算\n",
    "    model.train()\n",
    "    for batch_idx, (data_input, true_label) in enumerate(train_loader):\n",
    "        # 从数据加载器读取一个batch\n",
    "        # 把数据上载到GPU（如有）\n",
    "        data_input, true_label = data_input.to(device), true_label.to(device)\n",
    "        # 求解器初始化（每个batch初始化一次）\n",
    "        optimizer.zero_grad()\n",
    "        # 正向传播：模型由输入预测输出\n",
    "        output = model(data_input)\n",
    "        # 计算loss\n",
    "        loss = loss_fn(output, true_label)\n",
    "        # 反向传播：计算当前batch的loss的梯度\n",
    "        loss.backward()\n",
    "        # 由求解器根据梯度更新模型参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 间隔性的输出当前batch的训练loss\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data_input), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4914805.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 343804.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 997949.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 7520935.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.287443\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.284967\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.273498\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.022655\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.680804\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.322924\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.978829\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.955913\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.670626\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.821396\n",
      "\n",
      "Test set: Average loss: 0.5133, Accuracy: 8524/10000 (85%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.740045\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.698195\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.676256\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.531444\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.457620\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.622829\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.354776\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.588438\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.530390\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.532874\n",
      "\n",
      "Test set: Average loss: 0.3202, Accuracy: 9037/10000 (90%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.424804\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.300566\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.329820\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.363803\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.386950\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.435891\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.266594\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.464383\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.264058\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.480446\n",
      "\n",
      "Test set: Average loss: 0.2456, Accuracy: 9261/10000 (93%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.344691\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.222303\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.200596\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.300936\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.282076\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.424593\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.161063\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.374423\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.273447\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.498040\n",
      "\n",
      "Test set: Average loss: 0.2007, Accuracy: 9389/10000 (94%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.175686\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.350296\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.231449\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.277996\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.248128\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.339591\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.174389\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.384094\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.238967\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.279552\n",
      "\n",
      "Test set: Average loss: 0.1719, Accuracy: 9462/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 计算在测试集的准确率和loss\n",
    "def test(model, loss_fn, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_fn(output, target, reduction='sum').item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 检查是否有GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    # 设置随机种子（以保证结果可复现）\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    # 训练设备（GPU或CPU）\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # 设置batch size\n",
    "    train_kwargs = {'batch_size': BATCH_SIZE}\n",
    "    test_kwargs = {'batch_size': TEST_BACTH_SIZE}\n",
    "\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    # 数据预处理（转tensor、数值归一化）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    # 自动下载MNIST数据集\n",
    "    dataset_train = datasets.MNIST('data', train=True, download=True,\n",
    "                                   transform=transform)\n",
    "    dataset_test = datasets.MNIST('data', train=False,\n",
    "                                  transform=transform)\n",
    "\n",
    "    # 定义数据加载器（自动对数据加载、多线程、随机化、划分batch、等等）\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset_test, **test_kwargs)\n",
    "\n",
    "    # 创建神经网络模型\n",
    "    model = FeedForwardNet().to(device)\n",
    "\n",
    "    # 指定求解器\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "    # 定义loss函数\n",
    "    # 注：nll 作用于 log_softmax 等价于交叉熵，感兴趣的同学可以自行推导\n",
    "    # https://blog.csdn.net/weixin_38145317/article/details/103288032\n",
    "    loss_fn = F.nll_loss\n",
    "\n",
    "    # 训练N个epoch\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(model, loss_fn, device, train_loader, optimizer, epoch)\n",
    "        test(model, loss_fn, device, test_loader)\n",
    "        # scheduler.step()\n",
    "        \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-zhipu-Ddey8KS3-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
