{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch中的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义张量\n",
    "\n",
    "- 将已有数值转换为张量\n",
    "- 根据指定形状、类型生成张量\n",
    "- 根据指定形状生成固定值的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从数值转换张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 从标量\n",
    "print(torch.tensor(5))\n",
    "\n",
    "# 从数组\n",
    "b = np.asarray([4, 5, 6])\n",
    "print(torch.tensor(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据形状和类型生成张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 默认输出类型：torch.float32\n",
    "import torch\n",
    "print(torch.get_default_dtype())\n",
    "print(torch.Tensor([1, 3]).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 修改默认输出\n",
    "torch.set_default_dtype(torch.float64)\n",
    "print(torch.get_default_dtype())\n",
    "print(torch.Tensor([1, 3]).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.9447e-310, 6.9447e-310])\n",
      "tensor([[6.9447e-310, 6.0577e-316]])\n",
      "tensor([2.])\n",
      "tensor([1., 2.])\n"
     ]
    }
   ],
   "source": [
    "# 指定张量的形状\n",
    "print(torch.Tensor(2))\n",
    "print(torch.Tensor(1, 2))\n",
    "print(torch.Tensor([2]))\n",
    "print(torch.Tensor([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9661, 0.9740, 0.4645],\n",
       "        [0.4900, 0.7924, 0.8380]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用随机数填充\n",
    "torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据形状生成固定值的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.ones() 值为1\n",
    "- torch.zeros() 值为0\n",
    "- torch.ones_like() 与目标张量形状相同、值为1\n",
    "- torch.zeros_like() 与目标张量形状相同、值为0\n",
    "- torch.randn() 随机数\n",
    "- torch.eye() 生成对角矩阵\n",
    "- torch.full() 所有元素为指定值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "zeros:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "ones_like:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "zeros_like:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "randn:\n",
      " tensor([[ 2.0313,  0.3689, -0.4313],\n",
      "        [ 0.0216, -1.9894,  0.8077],\n",
      "        [-0.2210,  1.0119,  0.1432]])\n",
      "eye:\n",
      " tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "full:\n",
      " tensor([[7, 7, 7],\n",
      "        [7, 7, 7],\n",
      "        [7, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个形状为(3, 3)的张量，所有元素都为1\n",
    "ones = torch.ones((3, 3))\n",
    "print(\"ones:\\n\", ones)\n",
    "\n",
    "# 创建一个形状为(3, 3)的张量，所有元素都为0\n",
    "zeros = torch.zeros((3, 3))\n",
    "print(\"zeros:\\n\", zeros)\n",
    "\n",
    "# 创建一个与ones形状相同的张量，所有元素都为1\n",
    "ones_like = torch.ones_like(ones)\n",
    "print(\"ones_like:\\n\", ones_like)\n",
    "\n",
    "# 创建一个与zeros形状相同的张量，所有元素都为0\n",
    "zeros_like = torch.zeros_like(zeros)\n",
    "print(\"zeros_like:\\n\", zeros_like)\n",
    "\n",
    "# 创建一个形状为(3, 3)的张量，所有元素都是从标准正态分布中随机采样的\n",
    "randn = torch.randn((3, 3))\n",
    "print(\"randn:\\n\", randn)\n",
    "\n",
    "# 创建一个形状为(3, 3)的单位矩阵\n",
    "eye = torch.eye(3)\n",
    "print(\"eye:\\n\", eye)\n",
    "\n",
    "# 创建一个形状为(3, 3)的张量，所有元素都为7\n",
    "full = torch.full((3, 3), 7)\n",
    "print(\"full:\\n\", full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成随机张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9782425656273393658"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "torch.initial_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定形状生成随机值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6046,  0.1257,  0.7042],\n",
       "        [-3.2458, -0.7085, -1.7238]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成线性空间的随机值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 5, 9])\n",
      "tensor([ 1.,  4.,  7., 10.])\n"
     ]
    }
   ],
   "source": [
    "# 按照步长为2进行取值\n",
    "print(torch.arange(1, 10, step=4))\n",
    "\n",
    "# 均匀取出5个值\n",
    "print(torch.linspace(1, 10, steps=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成对数空间的随机值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+01, 1.7783e+03, 3.1623e+05, 5.6234e+07, 1.0000e+10])\n"
     ]
    }
   ],
   "source": [
    "print(torch.logspace(1, 10, steps=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成未初始化的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.empty(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更多的随机值生成函数\n",
    "\n",
    "- bernouli() 伯努力分布\n",
    "- cauchy() 柯西分布\n",
    "- exponential() 指数分布\n",
    "- geometric() 几何分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量的基本操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获得张量中元素的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor(2)\n",
    "print(torch.numel(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量的判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor(2)\n",
    "print(torch.is_tensor(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量的类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 使用type()方法转换类型\n",
    "a = torch.FloatTensor([4])\n",
    "print(a.type(torch.IntTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4], dtype=torch.int32)\n",
      "tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "# 也可以按如下方式写\n",
    "print(a.int())\n",
    "print(a.double())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重载操作符函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n",
      "tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor([4])\n",
    "print(a)\n",
    "b = torch.add(a, a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "torch.add(a, a, out=b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch重载了许多Python的操作符，可以直接在张量上使用这些操作符：\n",
    "\n",
    "1. **算术操作符**：`+`（加法）、`-`（减法）、`*`（乘法）、`/`（除法）、`//`（整除）、`%`（取余）、`**`（幂运算）。\n",
    "\n",
    "2. **比较操作符**：`>`（大于）、`<`（小于）、`>=`（大于等于）、`<=`（小于等于）、`==`（等于）、`!=`（不等于）。\n",
    "\n",
    "3. **逻辑操作符**：`&`（逻辑与）、`|`（逻辑或）、`^`（逻辑异或）、`~`（逻辑非）。\n",
    "\n",
    "4. **位移操作符**：`>>`（右移）、`<<`（左移）。\n",
    "\n",
    "5. **矩阵乘法操作符**：`@`。\n",
    "\n",
    "这些操作符都是元素级别的，也就是说，它们会对两个张量的对应元素进行操作。例如，`a + b`会返回一个新的张量，这个张量的每个元素都是`a`和`b`的对应元素的和。\n",
    "\n",
    "此外，PyTorch还重载了一些Python的内置函数，如`abs`、`len`、`str`、`float`等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自变化运算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20.])\n"
     ]
    }
   ],
   "source": [
    "# 原地修改\n",
    "a.add_(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更多数学运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.)\n",
      "tensor([4.4721])\n"
     ]
    }
   ],
   "source": [
    "print(a.mean())\n",
    "print(a.sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量与Numpy间的相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = torch.FloatTensor([4])\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4])\n",
      "tensor([4])\n"
     ]
    }
   ],
   "source": [
    "# numpy -> torch\n",
    "b = np.asarray([4])\n",
    "print(torch.from_numpy(b))\n",
    "print(torch.tensor(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 形状获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- pytorch ----------\n",
      "torch.Size([2, 2]) torch.Size([2, 2])\n",
      "---------- numpy ----------\n",
      "(2, 2) 4\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*10, \"pytorch\", \"-\"*10)\n",
    "x = torch.rand(2, 2)\n",
    "print(x.shape, x.size())\n",
    "\n",
    "print(\"-\"*10, \"numpy\", \"-\"*10)\n",
    "y = np.asarray([[4, 5], [5, 4]])\n",
    "print(y.shape, y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切片：与bumpy几乎一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4579],\n",
      "        [0.5331]])\n",
      "[4 2]\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 1)\n",
    "print(x[:])\n",
    "\n",
    "y = np.asarray([4, 2])\n",
    "print(y[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量与Numpy相互转换的陷阱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将Numpy转换为PyTorch张量时，按照读时引用、写时复制的机制\n",
    "- 将PyTorch张量转换为Numpy时，按照读时引用、写时原地修改的机制（**注意，这可能是一个陷阱**）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "tensor([2, 2])\n",
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1, 1])\n",
    "x = torch.from_numpy(y)\n",
    "print(x) # 输出为 tensor([1, 1])\n",
    "\n",
    "y += 1\n",
    "print(x) # 输出为 tensor([2, 2])\n",
    "print(y) # 输出为 [2 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在CPU和GPU控制的内存中定义张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.FloatTensor([4])\n",
    "b = a.cuda()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接在 GPU 中定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([4], device=\"cuda\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 to() 方法指定设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([4])\n",
    "print(a)\n",
    "print(a.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 CUDA_VISIBLE_DEVICES 来指定设备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `python_dotenv` 管理环境变量，或使用下面的脚本：\n",
    "```shell\n",
    "CUDA_VISIBLE_DEVICES=0 python mytask.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量间的数据操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "print(torch.reshape(a, (1, -1))) # -1 被自动转换为4，因为 2x2 = 1x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# -1 代表该维度由系统自动计算\n",
    "print(a.reshape((1, -1)))\n",
    "print(a.view((1, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeeze() / unsqueeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 构造 2x2 的矩阵\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "print(a.shape)\n",
    "# 变换为 1x4 的矩阵\n",
    "b = torch.reshape(a, (1, -1))\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# 减少一个大小为1的维度\n",
    "print(torch.squeeze(b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 增加一个大小为1的维度\n",
    "print(torch.unsqueeze(b, 1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t() / transpose() 矩阵转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([[5, 6, 7], [2, 8, 0]])\n",
    "print(b.shape)\n",
    "\n",
    "# 用 t() 转置\n",
    "print(torch.t(b).shape)\n",
    "# 用 transpose() 转置\n",
    "print(torch.transpose(b, dim0=1, dim1=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### permute() 交换维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 2],\n",
       "        [6, 8],\n",
       "        [7, 0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以用于实现矩阵转置\n",
    "b.permute(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# 不过，更多用于任意的维度交换\n",
    "x = torch.randn(1, 2, 3)\n",
    "print(x.shape)\n",
    "print(x.permute(1, 2, 0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view() / contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[ 1.5474,  0.4929,  0.6593, -1.9054],\n",
      "        [ 1.9615,  1.1072, -1.0313, -0.7408],\n",
      "        [ 1.5718,  1.1386, -0.2428, -0.6373],\n",
      "        [ 1.5705,  1.1780,  0.1223, -0.5077]])\n",
      "y:\n",
      " tensor([[[ 1.5474,  0.4929,  0.6593, -1.9054],\n",
      "         [ 1.9615,  1.1072, -1.0313, -0.7408]],\n",
      "\n",
      "        [[ 1.5718,  1.1386, -0.2428, -0.6373],\n",
      "         [ 1.5705,  1.1780,  0.1223, -0.5077]]])\n",
      "z:\n",
      " tensor([[ 1.5474,  0.4929,  0.6593, -1.9054,  1.9615,  1.1072, -1.0313, -0.7408],\n",
      "        [ 1.5718,  1.1386, -0.2428, -0.6373,  1.5705,  1.1780,  0.1223, -0.5077]])\n",
      "Number of elements: 16\n"
     ]
    }
   ],
   "source": [
    "# 创建一个形状为(4, 4)的张量\n",
    "x = torch.randn(4, 4)\n",
    "print(\"x:\\n\", x)\n",
    "\n",
    "# 使用view函数改变张量的形状\n",
    "y = x.view(2, 2, 4)\n",
    "print(\"y:\\n\", y)\n",
    "\n",
    "# 使用view函数改变张量的形状\n",
    "z = x.view(-1, 8)  # -1表示该维度的大小由其他维度决定\n",
    "print(\"z:\\n\", z)\n",
    "\n",
    "# 使用view函数获取张量的元素数量\n",
    "num_elements = x.view(-1).size(0)\n",
    "print(\"Number of elements:\", num_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：view() 方法要求内存连续，无法处理已经应用过t()、transpose()、permute()等方法的张量**\n",
    "\n",
    "因此，view()有时需要与contiguous()一起搭配使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([8, 2])\n",
      "False\n",
      "True\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# 定义一个张量后，默认为连续内存\n",
    "print(x.is_contiguous())\n",
    "print(x.view(-1, 2).shape)\n",
    "\n",
    "c = x.t()\n",
    "# 转置过\n",
    "print(c.is_contiguous())\n",
    "\n",
    "# 重新处理为连续内存\n",
    "print(c.contiguous().is_contiguous())\n",
    "print(c.contiguous().view(-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cat() 连接数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "\n",
    "b = torch.tensor([\n",
    "    [5, 6],\n",
    "    [7, 8]\n",
    "])\n",
    "\n",
    "print(torch.cat([a, b], dim=0))\n",
    "print(torch.cat([a, b], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk() 分割数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1, 2],\n",
      "        [3, 4]]), tensor([[5, 6],\n",
      "        [7, 8]]))\n",
      "(tensor([[1],\n",
      "        [3],\n",
      "        [5],\n",
      "        [7]]), tensor([[2],\n",
      "        [4],\n",
      "        [6],\n",
      "        [8]]))\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6],\n",
    "    [7, 8],\n",
    "])\n",
    "\n",
    "# 沿着第 0 维度拆分为 2 个chunks\n",
    "print(torch.chunk(a, chunks=2, dim=0))\n",
    "# 沿着第 1 维度拆分为 2 个chunks\n",
    "print(torch.chunk(a, chunks=2, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split() 分割数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5],\n",
       "         [2]]),\n",
       " tensor([[6, 7],\n",
       "         [8, 0]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[5, 6, 7], [2, 8, 0]])\n",
    "\n",
    "# 沿着第 1 个维度，按照 split_size_or_sections 指定的形状拆分，拆分的余数被保留为最后一部份\n",
    "torch.split(b, split_size_or_sections=(1, 2), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gather() 提取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 5],\n",
      "        [8, 0]])\n",
      "tensor([[6, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([\n",
    "    [5, 6, 7],\n",
    "    [2, 8, 0]\n",
    "])\n",
    "\n",
    "print(torch.gather(b, dim=1, index=torch.tensor([[1, 0], [1, 2]])))\n",
    "print(torch.gather(b, dim=1, index=torch.tensor([[1, 0, 0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select() 过滤数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 8, 0]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 index_select 选择维度\n",
    "torch.index_select(b, dim=0, index=torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 8])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ge -> 大于等于, greater-equal\n",
    "torch.masked_select(b, b.ge(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 8])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b.ge(6) 等价于 b >= 6\n",
    "torch.masked_select(b, b >= 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nonzero() 找出非0值位置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[0, 0],\n",
      "        [1, 1],\n",
      "        [2, 2]])\n"
     ]
    }
   ],
   "source": [
    "eye = torch.eye(3)\n",
    "print(eye)\n",
    "\n",
    "# 找出非0的位置索引\n",
    "print(torch.nonzero(eye))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where() 根据条件取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[4, 9, 3],\n",
      "        [0, 3, 9],\n",
      "        [7, 3, 7]])\n",
      "y:\n",
      " tensor([[13, 11, 16],\n",
      "        [16, 19, 18],\n",
      "        [16, 16, 18]])\n",
      "z:\n",
      " tensor([[13,  9, 16],\n",
      "        [16, 19,  9],\n",
      "        [ 7, 16,  7]])\n"
     ]
    }
   ],
   "source": [
    "# 创建两个形状为(3, 3)的随机整数张量\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randint(low=0, high=10, size=(3, 3))\n",
    "y = torch.randint(low=10, high=20, size=(3, 3))\n",
    "print(\"x:\\n\", x)\n",
    "print(\"y:\\n\", y)\n",
    "\n",
    "# 创建一个条件\n",
    "condition = x >= 5\n",
    "\n",
    "# 使用torch.where函数过滤\n",
    "# 优先选择x中的满足contidion的元素，否则就使用y中的元素\n",
    "z = torch.where(condition, x, y)\n",
    "print(\"z:\\n\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clamp() 根据阈值截断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 3],\n",
       "        [2, 3, 5],\n",
       "        [5, 3, 5]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 超出阈值的元素替换为min或max指定的值\n",
    "torch.clamp(x, min=2, max=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### argmax() / argmin() 最大值、最小值的位置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果不指定维度，就当作1维来寻找\n",
    "x = torch.tensor([\n",
    "    [7, 5, 6],\n",
    "    [9, 3, 8]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(x))\n",
    "\n",
    "# 等同于\n",
    "print(torch.argmax(x.view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 沿着第0维寻找最大值\n",
    "torch.argmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
