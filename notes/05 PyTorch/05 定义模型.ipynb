{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e8c8e4-2e4f-4824-8be3-3b79b53643d8",
   "metadata": {},
   "source": [
    "# 定义模型结构的常用方法\n",
    "\n",
    "1. 从 Module 类定义模型\n",
    "2. 在 init 函数中定义网络层\n",
    "3. 在 forward 函数中处理网络层连接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf89a50-21d3-4889-8a98-3de48e9e24bc",
   "metadata": {},
   "source": [
    "## 使用Module类定义网络层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeff074-e774-4f8a-ae4a-6853b3482a2b",
   "metadata": {},
   "source": [
    "### 定义网络层方法1：Sequential模块\n",
    "在PyTorch中，Sequential是一个特殊的模块，它包含了其他模块，并按照它们被添加的顺序来执行它们的forward方法。<br>\n",
    "这使得我们可以轻松地构建像堆栈一样的模型。以下是一个使用Sequential的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "973122ac-6036-4f9a-9385-f0fca5363a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 10, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73e1077f-25f4-4752-9a4e-25d7c61d8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layers = nn.Sequential(OrderedDict([\n",
    "            ('conv', nn.Conv2d(3, 10, 3)),\n",
    "            ('relu', nn.ReLU()),\n",
    "            ('fc', nn.Linear(10, 2)),\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df75988-c9e0-4284-9488-34656db18031",
   "metadata": {},
   "source": [
    "### 定义网络层方法2：使用nn.ModuleList\n",
    "nn.ModuleList是一个包含多个模块的列表。<br>\n",
    "它可以包含任何类型的模块，并可以像普通Python列表一样进行索引。<br>\n",
    "以下是一个示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc6dd0a2-19f4-4662-bbee-7283e4c30ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.Conv2d(3, 10, 3), nn.ReLU(), nn.Linear(10, 2)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b16ee-7fb8-4db7-80da-ab583c7122e9",
   "metadata": {},
   "source": [
    "### 定义网络层方法3：使用nn.ModuleDict\n",
    "nn.ModuleDict是一个包含多个模块的字典。<br>\n",
    "它可以包含任何类型的模块，并可以像普通Python字典一样进行索引。<br>\n",
    "以下是一个示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f58ff4b-ca55-4b52-b306-78a011be4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layers = nn.ModuleDict({\n",
    "            'conv': nn.Conv2d(3, 10, 3),\n",
    "            'relu': nn.ReLU(),\n",
    "            'fc': nn.Linear(10, 2)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers['conv'](x)\n",
    "        x = self.layers['relu'](x)\n",
    "        x = self.layers['fc'](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62fe91-38ba-4328-a67e-a0322acf729c",
   "metadata": {},
   "source": [
    "### 定义网络层方法4：一般写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e719f28-1ea9-4e2d-85d1-d3c20b3641e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, inputdim, hiddendim, outputdim):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.Linear1 = nn.Linear(inputdim, hiddendim)\n",
    "        self.Linear2 = nn.Linear(hiddendim, outputdim)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eaa10057-0cc8-4d5d-9260-34ce4d297268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, inputdim, hiddendim, outputdim):\n",
    "        super(MyNet, self).__init__()\n",
    "        # ---- 与上面的写法等价\n",
    "        self.add_module(\"Linear1\", nn.Linear(inputdim, hiddendim))\n",
    "        self.add_module(\"Linear2\", nn.Linear(hiddendim, outputdim))\n",
    "        self.add_module(\"criterion\", nn.CrossEntropyLoss())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00840bc6-f9c1-4e75-9830-f7cda33f915d",
   "metadata": {},
   "source": [
    "### children()\n",
    "所有通过 `Module` 类定义的模型，都可以使用 `children()` 获得各层的信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d61fe2c-b0ab-479c-b801-71e3db117313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=3, bias=True)\n",
      "Linear(in_features=3, out_features=2, bias=True)\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "model = MyNet(2, 3, 2)\n",
    "for x in model.children():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057fd0f-a467-4d1d-bf01-1d404f8e1a89",
   "metadata": {},
   "source": [
    "### named_children()\n",
    "通过 `named_children` 可以获得各层的名字信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "852904c7-99a4-4fd4-bb9e-c9d849a4049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear1', Linear(in_features=2, out_features=3, bias=True))\n",
      "('Linear2', Linear(in_features=3, out_features=2, bias=True))\n",
      "('criterion', CrossEntropyLoss())\n"
     ]
    }
   ],
   "source": [
    "for x in model.named_children():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb4979-a146-4290-b91f-c6f06d56d59e",
   "metadata": {},
   "source": [
    "### modules()\n",
    "或者，通过 `modules` 获得更详细信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce1b3c7d-bdd8-4568-9734-de7ee4f3ae33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (Linear1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (Linear2): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "Linear(in_features=2, out_features=3, bias=True)\n",
      "Linear(in_features=3, out_features=2, bias=True)\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "for m in model.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531922f-eeb9-4374-993e-67c4354fc11c",
   "metadata": {},
   "source": [
    "## 为模型添加参数：Parameters\n",
    "\n",
    "Parameters是Variable的子类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f248e5-8e8e-41c2-a8db-804b1e0c92c7",
   "metadata": {},
   "source": [
    "### 为模型添加参数\n",
    "\n",
    "**在init函数中定义网络层时，已经自动将网络层的参数传递给模型。**\n",
    "\n",
    "### register_parameter()\n",
    "也可以通过 `register_parameter(name, param)` 向模型添加。<br>\n",
    "这也等价于 `self.p = Parameter(tensor)`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bcea7-9144-48bb-b00c-fd0ae62f7a8b",
   "metadata": {},
   "source": [
    "### register_buffer(name, tensor)\n",
    "如果需要在模型中保存状态，但不想作为模型参数，可以使用 `register_buffer(name, tensor)` 添加变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b78897b5-1e21-4502-bf0b-c94080491150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, inputdim, hiddendim, outputdim):\n",
    "        super(Net, self).__init__()\n",
    "        # ----\n",
    "        self.register_parameter('my_vector1', nn.Parameter(torch.randn(768, 3, 3)))\n",
    "        self.register_parameter('my_vector2', nn.Parameter(torch.randn(1024, 768)))\n",
    "        self.register_buffer('my_vector3', torch.tensor([2.0, 2.0]))\n",
    "\n",
    "m = Net(2, 2, 2)\n",
    "print(m.my_vector1.requires_grad) # 这是一个模型参数\n",
    "print(m.my_vector3.requires_grad) # 这是一个普通变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451020a9-de3c-4326-94ed-3aebbfc7deb9",
   "metadata": {},
   "source": [
    "## 从模型中获取参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f542c1-d014-4648-981c-722c104c53fe",
   "metadata": {},
   "source": [
    "### parameters() 列举参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4838841-05d1-44cc-9934-605d1534c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 3, 3])\n",
      "torch.Size([1024, 768])\n"
     ]
    }
   ],
   "source": [
    "for p in m.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80021ce1-2f15-4051-96eb-8789c8187aad",
   "metadata": {},
   "source": [
    "### named_parameters() 列举参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af8b5cf0-d70e-4e31-bc48-04c45f46e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_vector1 : / torch.Size([768, 3, 3])\n",
      "my_vector2 : / torch.Size([1024, 768])\n"
     ]
    }
   ],
   "source": [
    "for name, p in m.named_parameters():\n",
    "    print(name, \":\", \"/\", p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9bfeb5-f45c-4db6-a05a-4ed8f076db8c",
   "metadata": {},
   "source": [
    "### numel() 计算参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b4925c8-f956-432c-88bb-a48e99fc5e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型一共有 793344 个可训练参数！\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'模型一共有 {count_parameters(m)} 个可训练参数！')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b46e64-15fe-4bf1-b38e-842c69ea8d55",
   "metadata": {},
   "source": [
    "### state_dict() 获取模型全部参数\n",
    "**包括了模型参数（Parameters）和状态参数（Buffers）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca4dcf61-dbba-429c-81d6-48e5125e250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 3, 3])\n",
      "torch.Size([1024, 768])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "state = m.state_dict()\n",
    "for p in state:\n",
    "    print(state[p].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc260f7-c329-4fd9-938b-bf742646d456",
   "metadata": {},
   "source": [
    "**查看权重：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f794343-b015-4c44-9a39-a54537bd9608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3595,  0.5266],\n",
      "        [-0.1143,  0.0146],\n",
      "        [-0.2233,  0.1463],\n",
      "        [-0.2924, -0.5185],\n",
      "        [-0.3401,  0.3198]])\n",
      "tensor([-0.1163, -0.4208,  0.6642,  0.6232, -0.3497])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, inputdim, hiddendim, outputdim):\n",
    "        super(MyNet, self).__init__()\n",
    "        # ---- 与上面的写法等价\n",
    "        self.add_module(\"Linear1\", nn.Linear(inputdim, hiddendim))\n",
    "        self.add_module(\"Linear2\", nn.Linear(hiddendim, outputdim))\n",
    "        self.add_module(\"criterion\", nn.CrossEntropyLoss())\n",
    "\n",
    "model = MyNet(2, 5, 2)\n",
    "params = model.state_dict()\n",
    "print(params['Linear1.weight'])\n",
    "print(params['Linear1.bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2217092-4af3-4303-bfdb-5eef141d04ac",
   "metadata": {},
   "source": [
    "## 激活函数\n",
    "每个激活函数都有两种形式：\n",
    "- 类形式：在 torch.nn 模块中定义\n",
    "- 函数形式：在 torch.nn.functional 模块中定义\n",
    "\n",
    "因为激活函数通常都不会参与梯度计算，所以一般应当使用函数形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e4c178d6-043e-4d24-ac79-f9162aa84b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7616, 0.9640, 0.9951])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh = torch.nn.Tanh()\n",
    "tanh(torch.tensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa23907-dc1b-4761-b871-8941b699ed53",
   "metadata": {},
   "source": [
    "**下面写法达到效果类似，却完全不会参与梯度计算：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "00161bb0-bfa0-47e4-9ea7-d4dd751f6765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7616, 0.9640, 0.9951])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.tanh(torch.tensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14b77d-14af-47f0-a4f8-6bacc7f2ac04",
   "metadata": {},
   "source": [
    "## L2正则化\n",
    "PyTorch可以直接使用优化器中的 `weight_decay` 参数来指定权重衰减率，实现对权重 w 和 偏执 b 的L2正则化。\n",
    "\n",
    "**有时需要指定优化器配置，仅对权重 w 做正则化，而不处理偏置 b，以防止过拟合。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea4b70-7b61-4b5d-a3ae-5acab00d7397",
   "metadata": {},
   "source": [
    "## Dropout 函数\n",
    "Dropout同样有类形式和函数形式两种，与激活函数的情况类似，一般推荐用函数形式。\n",
    "- Dropout：对 1 维数据进行 Dropout 处理\n",
    "- Dropout2D：对 2 维数据进行 Dropout 处理\n",
    "- Dropout3D：对 3 维数据进行 Dropout 处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d758c02-f9ef-47ee-84cd-3283f69c0f3a",
   "metadata": {},
   "source": [
    "## 批量归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a017fa-e3c1-414d-96ee-dff3bc434116",
   "metadata": {},
   "source": [
    "### 三种批量归一化处理\n",
    "- BatchNorm1d: 处理2维或3维数据， `[N, D]`或`[N, D, L]`，N 批次，D 数据个数，L 数据长度\n",
    "- BatchNorm2d：处理4维数据, `[N, C, H, W]`，C 通道数，H 高度，W 宽度\n",
    "- BatchNorm3d：处理5维数据，`[N, C, D, H, W]`，D 深度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60842fc-753e-4cdc-8456-d6c653dcfb6e",
   "metadata": {},
   "source": [
    "### 手动实现批量归一化算法示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a6fdf-70c7-4cd9-af56-fb85fd53ba25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-chinese-py3.9-ipkyernel",
   "language": "python",
   "name": "langchain-chinese-py3.9-ipkyernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
